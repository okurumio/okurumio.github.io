---
title: CNN
date: 2023-06-02 13:15:48
permalink: /pages/e7bc1e/
categories:
  - ds
  - 深度学习
tags:
  - 
---
## CNN 
卷积神经网络（Convolutional Neural Networks）
1. **平移不变性**（translation invariance）：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”。
2. **局部性**（locality）：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则。最终，可以聚合这些局部特征，以在整个图像级别进行预测。  
>[卷积神经网络基础](http://ai-start.com/dl2017/html/lesson4-week1.html#header-n254)  
>[现代卷积神经网络](http://ai-start.com/dl2017/html/lesson4-week2.html)

### 卷积层
对图像进行边缘检测，提取图像的特征。  
**卷积类型**：full卷积，same卷积，valid卷积。  
```python
# 二维卷积
torch.nn.Conv2d(
	in_channels, 
	out_channels, 
	kernel_size, 
	stride=1, 
	padding=0, 
	dilation=1, 
	groups=1, 
	bias=True, 
	padding_mode='zeros', 
	device=None, 
	dtype=None
)
```
参数：
- in_channels：输入张量的channel数。
- out_channels：输出的张量的channel数。
- kernel_size：卷积核大小。
- stride：卷积步长。
- padding：填充大小。
- dilation：是否采用空洞卷积（默认为1不采用），卷积核中元素的间距。
- groups：是否分组卷积，输入与输出之间的通道数。
- bias：偏置。
### 池化层
卷积网络也经常使用池化层来缩减模型的大小，提高计算速度，同时提高所提取特征的鲁棒性。
```python
torch.nn.MaxPool2d(
	kernel_size, 
	stride=None, 
	padding=0, 
	dilation=1, 
	return_indices=False, 
	ceil_mode=False
)
```
参数：
- kernel_size：核大小。
- stride：步长。
- padding：填充大小。
- dilation：步幅。
- return_indices：返回输出最大值的序号。
### 全连接层
通过提取特征实现分类，起到分类器的作用。  
```python
self.fc = nn.Sequential(  
    nn.Linear(1024, 2),  
)
```
**线性层**
```python
torch.nn.Linear(
	in_features,
	out_features,
	bias=True
)
```
参数：
- in_features：输入的神经元个数
- out_features：输出神经元个数
- bias：是否包含偏置

### BN层
批量规范化（batch normalization）
```python
torch.nn.BatchNorm2d(
	 num_features, 
	 eps=1e-05, 
	 momentum=0.1, 
	 affine=True, 
	 track_running_stats=True, 
	 device=None, 
	 dtype=None
)
```

参数：
- num_features：输入特征数
- eps：稳定系数，防止分母出现0
- momentum：均值和方差更新时的参数。
- affine：gamma，beta是否可学
- track_running_stats：均值和方差是否需要更新

## CNN实现
### dataset
```python
class mydataset(Dataset):  
    def __init__(self, folder, transform=None):  
        self.train_image_file_paths = [os.path.join(folder, image_file) for image_file in os.listdir(folder)]  
        self.transform = transform  
      
    def __len__(self):  
        return len(self.train_image_file_paths)  
      
    def __getitem__(self, idx):  
        image_root = self.train_image_file_paths[idx]  
        image_name = image_root.split(os.path.sep)[-1]  
        image = Image.open(image_root)  
        if self.transform is not None:  
            image = self.transform(image)  
        label = ohe.encode(image_name.split('_')[0])  
        return image, label  
  
transform = transforms.Compose([  
    # transforms.ColorJitter(),py  
    transforms.Grayscale(),  
    transforms.ToTensor(),  
    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  
])  
  
def get_train_data_loader():  
    dataset = mydataset(setting.TRAIN_DATASET_PATH, transform=transform)  
    return DataLoader(dataset, batch_size=64, shuffle=True)  
  
def get_eval_data_loader():  
    dataset = mydataset(setting.EVAL_DATASET_PATH, transform=transform)  
    return DataLoader(dataset, batch_size=1, shuffle=True)  
  
def get_predict_data_loader():  
    dataset = mydataset(setting.PREDICT_DATASET_PATH, transform=transform)  
    return DataLoader(dataset, batch_size=1, shuffle=True)
```
### model
```python
class CNN(nn.Module):  
    def __init__(self):  
        super(CNN, self).__init__()  
        self.layer1 = nn.Sequential(  
            nn.Conv2d(1, 32, kernel_size=3, padding=1),  
            nn.BatchNorm2d(32),  
            nn.Dropout(0.5),  # drop 50% of the neuron  
            nn.ReLU(),  
            nn.MaxPool2d(2))   
        self.fc = nn.Sequential(  
            nn.Linear((setting.IMAGE_WIDTH // 8) * (setting.IMAGE_HEIGHT // 8) * 64, 1024),  
            nn.Dropout(0.5),  # drop 50% of the neuron  
            nn.ReLU())  
        self.rfc = nn.Sequential(  
            nn.Linear(1024, setting.MAX_CAPTCHA * setting.ALL_CHAR_SET_LEN),  
        )  
      
    def forward(self, x):  
        out = self.layer1(x)  
        out = out.view(out.size(0), -1)  
        out = self.fc(out)  
        out = self.rfc(out)  
        return out1·
```
### train
```python
num_epochs = 30  
batch_size = 100  
learning_rate = 0.001  
  
  
def main():  
    cnn = CNN()  
    cnn.train()  
  
    # 损失函数  
    criterion = nn.MultiLabelSoftMarginLoss()  
    # 梯度下降  
    optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)  
    max_eval_acc = -1  
  
    # 加载数据集  
    train_dataloader = dataset.get_train_data_loader()  
    for epoch in range(num_epochs):  
        for i, (images, labels) in enumerate(train_dataloader):  
            images = Variable(images)  
            labels = Variable(labels.float())  
            predict_labels = cnn(images)  
            loss = criterion(predict_labels, labels)  
            optimizer.zero_grad()  
            loss.backward()  
            optimizer.step()  
            if (i + 1) % 10 == 0:  
                print("epoch:", epoch, "step:", i, "loss:", loss.item())  
            if (i + 1) % 10 == 0:  
                # current is model.pkl  
                torch.save(cnn.state_dict(), "./model.pkl")  
                print("save model")  
        print("epoch:", epoch, "step:", i, "loss:", loss.item())  
        eval_acc = evaluate()  
        if eval_acc > max_eval_acc:  
            # best model save as best_model.pkl  
            torch.save(cnn.state_dict(), "./best_model.pkl")  
            print("save best model")  
    torch.save(cnn.state_dict(), "./model.pkl")  
    print("save last model")
```