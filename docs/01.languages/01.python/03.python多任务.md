---
title: python多任务
date: 2022-07-18 17:10:13
permalink: /language/python/concurrent/
tags: 
  - python
categories: 
  - python
---

## 概念
- **进程:** 是一个程序在一个数据集上的一次动态执行的过程，是操作系统进行资源分配和调度的一个独立单位。 一般由程序、数据集合和进程控制块(PCB)三部分组成。  
- **线程:** 是程序执行中一个单一的顺序控制流程，是程序执行流的最小单元，是处理器调度和分派的基本单位。一个标准的线程由线程ID、当前指令指针(PC)、寄存器和堆栈组成。而进程由内存空间(代码、数据、进程空间、打开的文件)和一个或多个线程组成。  
- **协程:** 是一种基于线程之上，但又比线程更加轻量级的存在，具有对内核来说不可见的特性。  
- **对比:**
  1. 线程是程序执行的最小单位，而进程是操作系统分配资源的最小单位；  
  2. 进程之间相互独立，但同一进程下的各个线程之间共享程序的内存空间及一些进程级的资源；  
  3. 线程的切换由操作系统负责调度，协程由用户自己进行调度，因此减少了上下文切换，提高了效率；  
  4. 线程的默认Stack大小是1M，而协程更轻量，接近1K。因此可以在相同的内存中开启更多的协程；
  5. 对于非io阻塞的操作，线程相较于协程，能更公平的分配对资源的控制权，这是因为语言层相较于用户层，语言层能更好的感知到多个线程的运行状态，并在掌握更多信息的前提下（线程运行的字节码和时长），进行更加合理的GIL的获取和释放。
  6. python的协程间切换主要是应用层面上的。对于io阻塞的操作，协程相较于线程，能更精确的获取（或者释放）对资源的控制权，这是因为用户层相较于语言层，用户层能更好的感知特定操作的时机。
## 多进程
### multiprocessing
```python
from multiprocessing import Process

def task(i):
    print(i)
    
if __name__ == '__main__':
    for i in range(10):
        p = Process(target=task, args=(i,))
        p.start()
        p.join()
```
**Python多进程可以选择两种创建进程的方式:**  
- 分支创建：fork会直接复制一份自己给子进程运行，并把自己所有资源的handle 都让子进程继承，因而创建速度很快，但更占用内存资源。  
`multiprocessing.set_start_method('spawn')  # default on WinOS or MacOS`  
- 分产创建：spawn只会把必要的资源的handle 交给子进程，因此创建速度稍慢。  
`multiprocessing.set_start_method('fork')   # default on Linux (UnixOS)`  
### 进程池
```python
from multiprocessing import Pool

def task(dict):
    print(dict)

def run__pool():
    cpu_worker_num = 2
    process_args = [{'id':1}, {'id':2}]

    with Pool(cpu_worker_num) as p:
        outputs = p.map(task, process_args)

if __name__ =='__main__':
    run__pool()
```
### 管道 Pipe
```python
from multiprocessing import Process, Pipe

def task1(conn, p_id):
    conn.send(f'{p_id}_send1')
    print(p_id, 'send1')

    rec = conn.recv()
    print(p_id, 'recv', rec)

def task2(conn, p_id):
    conn.send(p_id)
    print(p_id, 'send')
    
    rec = conn.recv()
    print(p_id, 'recv', rec)

def run__pipe():
    conn1, conn2 = Pipe()

    process = [Process(target=task1, args=(conn1, 'I1')),
               Process(target=task2, args=(conn2, 'I2')),]
    [p.start() for p in process]
    conn1.send(None)
    [p.join() for p in process]

if __name__ =='__main__':
    run__pipe()
```
## 多线程
- **守护线程：** 只有所有守护线程都结束，整个Python程序才会退出，但并不是说Python程序会等待守护线程运行完毕，相反，当程序退出时，如果还有守护线程在运行，程序会去强制终结所有守护线程，当守所有护线程都终结后，程序才会真正退出。可以通过修改daemon属性或者初始化线程时指定daemon参数来指定某个线程为守护线程。  
- **非守护线程：** 一般创建的线程默认就是非守护线程，包括主线程也是，即在Python程序退出时，如果还有非守护线程在运行，程序会等待直到所有非守护线程都结束后才会退出。
### threading
**线程类**
```python
import time
import threading

class MyThread(threading.Thread):
    def __init__(self, i):
        threading.Thread.__init__(self)
        self.threadId = i

    def run(self):
        print('thread{}'.format(self.threadId))
        time.sleep(3)
        
spiders = []
for i in range(3):
    spiders.append(MyThread(i))
for spider in spiders:
    spider.start()
for spider in spiders:
    spider.join()
```
**with:** 当进入with语句块时，acquire()方法被自动调用，当离开with语句块时，release()语句块被自动调用。包括Lock、RLock、Condition、Semaphore。
### 锁
**互斥锁**
```python
lock = threading.Lock()

def run():
    lock.acquire()
    time.sleep(3)
    lock.release()
# 如果是使用的两个普通锁，那么就会造成死锁的情况，程序一直阻塞而不会退出
# lock1 = threading.Lock()
# lock2 = threading.Lock()
```
**递归锁**  
加入了“所属线程”和“递归等级”的概念，释放锁必须有获取锁的线程来进行释放，同时同一个线程在释放锁之前再次获取锁将不会阻塞当前线程，只是在锁的递归等级上加了1（获得锁时的初始递归等级为1）。
```python
lock1 = lock2 = threading.RLock()
def run():
    lock1.acquire()
    lock2.acquire()
    time.sleep(3)
    lock2.release()
    lock1.release()
```
**条件锁**  
待完成

**事件锁**  
一个事件对象管理一个内部标志，初始状态默认为False，set()方法可将它设置为True，clear()方法可将它设置为False，wait()方法将线程阻塞直到内部标志的值为True
```python
class spider(threading.Thread):
    def __init__(self, n, event):
        super().__init__()
        self.n = n
        self.event = event
        
    def run(self):
        print(f'第{self.n}号爬虫已就位！')
        self.event.wait()
        print(f'信号标记变为True！！第{self.n}号爬虫开始运行')

eve = threading.Event()
for num in range(10):
    crawler = spider(num, eve)
    crawler.start()

    input('按下回车键，启动所有爬虫！')
    # 释放锁
    eve.set()
    time.sleep(10)
```
**信号量锁**  
一个信号量管理一个内部计数器，acquire()方法会减少计数器，release()方法则增加计数器，计数器的值永远不会小于零，当调用acquire()时，如果发现该计数器为零，则阻塞线程，直到调用release()方法使计数器增加。
```python
# 限制线程数量
sem = threading.Semaphore(2)

class MyThread(threading.Thread):
    def __init__(self, i):
        threading.Thread.__init__(self)
        self.threadId = i

    def run(self):
        with sem:
            time.sleep(3)
```
### 线程池
```python
from multiprocessing.dummy import Pool as ThreadPool

def get_title(i):
    url = 'https://movie.douban.com/top250?start={}&filter='.format(i*25)
    r = requests.get(url)

pool = ThreadPool()
print(pool.map(get_title, range(10)))
```
## 多协程
### asyncio高级使用
- **run:** 创建事件循环，运行一个协程，关闭事件循环。
- **create_task:** 将协程包装成task。
- **gather:** 并发运行任务。
  1. gather任务无法取消。
  2. 返回值是一个结果列表。
  3. 可以按照传入参数的 顺序，顺序输出。
- **Semaphore:** 限制协程数量。
```python
import asyncio
sem = asyncio.Semaphore(3)

async def requests(i):
	async with sem:
		print('启动协程{}'.format(i))
        await asyncio.sleep(3)
        
async def main():
    tasks = []
    for i in range(5):
        tasks.append(asyncio.create_task(request(i)))
    await asyncio.gather(*tasks)

if __name__ == '__main__':
	asyncio.run(main())
```
- **current_task:** 返回当前正在运行的task实例。  
- **all_tasks:** 返回一组尚未完成的task。
- **wait:** 并发运行任务。 
  1. 内部用一个set集合保存它创建的Task实例，所以任务不是顺序执行。
  2. 返回值是一个元组，包括两个集合，分别表示已完成和未完成的任务。
- **shield:** 取消屏蔽，如果一个创建后就不希望被任何情况取消，可以使用asyncio.shield保护任务能顺利完成。
```python
task1 = asyncio.shield(a())
task2 = loop.create_task(b())
ts = asyncio.gather(task1, task2, return_exceptions=True)
task1.cancel()
```
### asyncio底层使用
- **get_running_loop():** 返回当前 OS 线程中正在运行的事件循环
- **get_event_loop():** 获取事件循环实例
- **new_event_loop():** 创建一个新的事件循环
- **run_until_complete():** 运行一个任务
```python
async def test(i):  
    print('启动协程{}'.format(i))  
    await asyncio.sleep(3)  
    return 'success'  
  
def callback(future):  
    print('Callback: ', future.result())  
  
loop = asyncio.new_event_loop()  
task = loop.create_task(test(1))  
task.add_done_callback(callback)  
loop.run_until_complete(task)
```